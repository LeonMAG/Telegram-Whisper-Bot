import os
import logging
import tempfile
from openai import OpenAI
from telegram import Update
from telegram.ext import Application, CommandHandler, MessageHandler, filters, ContextTypes

# ‚îÄ‚îÄ Configuraci√≥n ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
TELEGRAM_TOKEN = os.environ.get("TELEGRAM_TOKEN")
OPENAI_API_KEY = os.environ.get("OPENAI_API_KEY")

if not TELEGRAM_TOKEN or not OPENAI_API_KEY:
    raise SystemExit(
        "‚ùå Faltan variables de entorno obligatorias.\n"
        "   Configura TELEGRAM_TOKEN y OPENAI_API_KEY antes de ejecutar el bot.\n"
        "   En local: export TELEGRAM_TOKEN=tu_token && export OPENAI_API_KEY=tu_key\n"
        "   En Railway: a√±√°delas en la pesta√±a Variables del servicio."
    )

WHISPER_MODEL = "whisper-1"
MAX_FILE_SIZE_MB = 25
client = OpenAI(api_key=OPENAI_API_KEY)

logging.basicConfig(
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    level=logging.INFO,
)
logger = logging.getLogger(__name__)


async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text(
        "üéôÔ∏è *Bot de Transcripci√≥n de Audio*\n\n"
        "Env√≠ame una nota de voz o un archivo de audio (MP3, M4A, WAV, OGG‚Ä¶) "
        "y te devolver√© la transcripci√≥n en texto usando Whisper de OpenAI.\n\n"
        "üìå *L√≠mite:* 25 MB por archivo.\n"
        "üåê *Idioma:* Detecci√≥n autom√°tica.",
        parse_mode="Markdown",
    )


async def help_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text(
        "üìñ *Ayuda*\n\n"
        "‚Ä¢ Env√≠a una *nota de voz* directamente.\n"
        "‚Ä¢ Env√≠a un *archivo de audio* (MP3, WAV, M4A, OGG, FLAC, WEBM).\n"
        "‚Ä¢ Recibir√°s un mensaje de \"Procesando...\" y luego la transcripci√≥n.\n\n"
        "Si algo falla, recibir√°s el error detallado con pistas para solucionarlo.",
        parse_mode="Markdown",
    )


def transcribe_audio(file_path: str) -> str:
    with open(file_path, "rb") as audio_file:
        transcript = client.audio.transcriptions.create(
            model=WHISPER_MODEL,
            file=audio_file,
        )
    return transcript.text.strip()


async def handle_audio(update: Update, context: ContextTypes.DEFAULT_TYPE):
    message = update.message

    if message.voice:
        file_obj = message.voice
        file_name = "voice.ogg"
        file_size = file_obj.file_size
    elif message.audio:
        file_obj = message.audio
        file_name = message.audio.file_name or "audio.mp3"
        file_size = file_obj.file_size
    elif message.document and message.document.mime_type and message.document.mime_type.startswith("audio/"):
        file_obj = message.document
        file_name = message.document.file_name or "audio.bin"
        file_size = file_obj.file_size
    elif message.video_note:
        file_obj = message.video_note
        file_name = "video_note.mp4"
        file_size = file_obj.file_size
    else:
        return

    if file_size and file_size > MAX_FILE_SIZE_MB * 1024 * 1024:
        await message.reply_text(
            f"‚ö†Ô∏è El archivo supera el l√≠mite de {MAX_FILE_SIZE_MB} MB permitido por Whisper.\n"
            f"Tama√±o recibido: {file_size / (1024*1024):.1f} MB."
        )
        return

    processing_msg = await message.reply_text("‚è≥ *Procesando audio‚Ä¶*", parse_mode="Markdown")

    tmp_path = None
    try:
        tg_file = await file_obj.get_file()
        with tempfile.NamedTemporaryFile(suffix=f"_{file_name}", delete=False) as tmp:
            tmp_path = tmp.name
            await tg_file.download_to_drive(tmp_path)

        text = transcribe_audio(tmp_path)

        if not text:
            await processing_msg.edit_text("‚ö†Ô∏è La transcripci√≥n est√° vac√≠a. El audio podr√≠a no contener voz reconocible.")
            return

        MAX_MSG_LEN = 4000
        if len(text) <= MAX_MSG_LEN:
            await message.reply_text(text)
        else:
            parts = [text[i:i + MAX_MSG_LEN] for i in range(0, len(text), MAX_MSG_LEN)]
            for idx, part in enumerate(parts, 1):
                await message.reply_text(part)

        await processing_msg.delete()

    except Exception as e:
        logger.error(f"Error transcribiendo audio: {e}", exc_info=True)
        error_text = str(e)

        help_hint = ""
        if "401" in error_text or "Incorrect API key" in error_text:
            help_hint = (
                "\n\nüîé *Posible causa:* API key de OpenAI inv√°lida o expirada.\n"
                "üí° *Soluci√≥n:* Verifica tu clave en https://platform.openai.com/api-keys"
            )
        elif "429" in error_text or "rate limit" in error_text.lower():
            help_hint = (
                "\n\nüîé *Posible causa:* Has superado el l√≠mite de uso de la API.\n"
                "üí° *Soluci√≥n:* Espera unos minutos o revisa tu plan en https://platform.openai.com/usage"
            )
        elif "413" in error_text or "too large" in error_text.lower():
            help_hint = (
                "\n\nüîé *Posible causa:* El archivo es demasiado grande para Whisper (m√°x. 25 MB).\n"
                "üí° *Soluci√≥n:* Comprime el audio o div√≠delo en partes m√°s cortas."
            )
        elif "insufficient_quota" in error_text.lower():
            help_hint = (
                "\n\nüîé *Posible causa:* No tienes cr√©ditos suficientes en OpenAI.\n"
                "üí° *Soluci√≥n:* A√±ade saldo en https://platform.openai.com/settings/organization/billing/overview"
            )
        elif "timeout" in error_text.lower() or "timed out" in error_text.lower():
            help_hint = (
                "\n\nüîé *Posible causa:* El audio es muy largo y la API tard√≥ demasiado.\n"
                "üí° *Soluci√≥n:* Intenta con un audio m√°s corto (< 10 min recomendado)."
            )
        else:
            help_hint = (
                "\n\nüîé *Para investigar:* Busca el error en Google con:\n"
                f"`OpenAI Whisper API {error_text[:80]}`"
            )

        await processing_msg.edit_text(
            f"‚ùå *Error al transcribir:*\n\n`{error_text[:500]}`{help_hint}",
            parse_mode="Markdown",
        )

    finally:
        if tmp_path:
            try:
                os.unlink(tmp_path)
            except Exception:
                pass


async def handle_unknown(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text(
        "üéôÔ∏è Env√≠ame una *nota de voz* o un *archivo de audio* para transcribirlo.",
        parse_mode="Markdown",
    )


def main():
    app = Application.builder().token(TELEGRAM_TOKEN).build()

    app.add_handler(CommandHandler("start", start))
    app.add_handler(CommandHandler("help", help_command))

    app.add_handler(MessageHandler(filters.VOICE, handle_audio))
    app.add_handler(MessageHandler(filters.AUDIO, handle_audio))
    app.add_handler(MessageHandler(
        filters.Document.MimeType("audio/mpeg") |
        filters.Document.MimeType("audio/mp4") |
        filters.Document.MimeType("audio/ogg") |
        filters.Document.MimeType("audio/wav") |
        filters.Document.MimeType("audio/x-wav") |
        filters.Document.MimeType("audio/flac") |
        filters.Document.MimeType("audio/webm") |
        filters.Document.MimeType("audio/x-m4a") |
        filters.Document.MimeType("audio/aac") |
        filters.Document.MimeType("video/mp4"),
        handle_audio
    ))
    app.add_handler(MessageHandler(filters.VIDEO_NOTE, handle_audio))
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_unknown))

    logger.info("üöÄ Bot iniciado. Esperando mensajes...")
    app.run_polling(allowed_updates=Update.ALL_TYPES)


if __name__ == "__main__":
    main()
